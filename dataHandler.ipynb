{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5300a851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "from datetime import datetime, time\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "current_folder_path = os.path.abspath('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f4dad1",
   "metadata": {},
   "source": [
    "## CSV data\n",
    "#### Train events\n",
    "Contains the target data, ie the *starting to sleep* and *waking up* events.\n",
    "- **series_id** : unique subject id, primary key when linked to the **train_series** parquet data  \n",
    "- **night** : counts the nth night of the serie  \n",
    "- **event** : target of the studie, with to values : *onset* and *wakeup*  \n",
    "- **step**: gives the index sample data corresponding to the event in the of the **train_series** parquet data. When multiplied by 5, gives the equivalent lasted time since the begining of the studie on the current test subject.  \n",
    "- **timestamp** : datetime object, exact time of the event, presented in the form of yyyy-mm-ddThh-mm-ss-utc\n",
    "\n",
    "#### Sample submission\n",
    "An example of the format in which the aswer data should be submitted to be evaluated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "226de7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>night</th>\n",
       "      <th>event</th>\n",
       "      <th>step</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>1</td>\n",
       "      <td>onset</td>\n",
       "      <td>4992.0</td>\n",
       "      <td>2018-08-14T22:26:00-0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>1</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>10932.0</td>\n",
       "      <td>2018-08-15T06:41:00-0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>2</td>\n",
       "      <td>onset</td>\n",
       "      <td>20244.0</td>\n",
       "      <td>2018-08-15T19:37:00-0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>2</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>27492.0</td>\n",
       "      <td>2018-08-16T05:41:00-0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>3</td>\n",
       "      <td>onset</td>\n",
       "      <td>39996.0</td>\n",
       "      <td>2018-08-16T23:03:00-0400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      series_id  night   event     step                 timestamp\n",
       "0  038441c925bb      1   onset   4992.0  2018-08-14T22:26:00-0400\n",
       "1  038441c925bb      1  wakeup  10932.0  2018-08-15T06:41:00-0400\n",
       "2  038441c925bb      2   onset  20244.0  2018-08-15T19:37:00-0400\n",
       "3  038441c925bb      2  wakeup  27492.0  2018-08-16T05:41:00-0400\n",
       "4  038441c925bb      3   onset  39996.0  2018-08-16T23:03:00-0400"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_events = pd.read_csv(current_folder_path + \"/train_events.csv\").dropna()\n",
    "df_train_events.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42f0a00",
   "metadata": {},
   "source": [
    "#### Timestamp conversion\n",
    "The timestamps are converted to instant of the day, as the date doesn't matter when sstudying daily events such as going to bed and waking up.\n",
    "Thus, the timestamps of every sleeping events, for every test subject (series_id) are converted in seconds//5.\n",
    "To get the time in hour format, the following retreiving operation can easily be computed :\n",
    "```python\n",
    "real_seconds = seconds * 5 \n",
    "h = real_seconds // 3600\n",
    "m = (real_seconds - h*3600) // 60\n",
    "s = (real_seconds - h*3600 - m*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "785191ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:1:1\n"
     ]
    }
   ],
   "source": [
    "#Eg: 01:01:01 ie, 720*5 + 12*5 + 0.2*5 = 3600 + 60 + 1 = 1h + 1m + 1s\n",
    "\n",
    "seconds = 720 + 12 + 0.2\n",
    "real_seconds = seconds * 5 \n",
    "h = round(real_seconds // 3600)\n",
    "m = round((real_seconds - h*3600) // 60)\n",
    "s = round(real_seconds - h*3600 - m*60)\n",
    "\n",
    "print(f\"{h}:{m}:{s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c2be7f",
   "metadata": {},
   "source": [
    "## Target data editing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "748d77e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test subjects studied : 269 unique id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 269/269 [00:00<00:00, 456.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>night</th>\n",
       "      <th>event</th>\n",
       "      <th>step</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>timestamp (hh:mm:ss)</th>\n",
       "      <th>timestamp (seconds/5)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4992.0</td>\n",
       "      <td>2018-08-14T22:26:00-0400</td>\n",
       "      <td>22:26:00</td>\n",
       "      <td>16152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10932.0</td>\n",
       "      <td>2018-08-15T06:41:00-0400</td>\n",
       "      <td>06:41:00</td>\n",
       "      <td>4812.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20244.0</td>\n",
       "      <td>2018-08-15T19:37:00-0400</td>\n",
       "      <td>19:37:00</td>\n",
       "      <td>14124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27492.0</td>\n",
       "      <td>2018-08-16T05:41:00-0400</td>\n",
       "      <td>05:41:00</td>\n",
       "      <td>4092.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39996.0</td>\n",
       "      <td>2018-08-16T23:03:00-0400</td>\n",
       "      <td>23:03:00</td>\n",
       "      <td>16596.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      series_id  night  event     step                 timestamp  \\\n",
       "0  038441c925bb    1.0    0.0   4992.0  2018-08-14T22:26:00-0400   \n",
       "1  038441c925bb    1.0    1.0  10932.0  2018-08-15T06:41:00-0400   \n",
       "2  038441c925bb    2.0    0.0  20244.0  2018-08-15T19:37:00-0400   \n",
       "3  038441c925bb    2.0    1.0  27492.0  2018-08-16T05:41:00-0400   \n",
       "4  038441c925bb    3.0    0.0  39996.0  2018-08-16T23:03:00-0400   \n",
       "\n",
       "  timestamp (hh:mm:ss)  timestamp (seconds/5)  \n",
       "0             22:26:00                16152.0  \n",
       "1             06:41:00                 4812.0  \n",
       "2             19:37:00                14124.0  \n",
       "3             05:41:00                 4092.0  \n",
       "4             23:03:00                16596.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated data saved as 'train_events_updated.csv'\n"
     ]
    }
   ],
   "source": [
    "show_data = 0\n",
    "\n",
    "# Converted timestamps storing df init\n",
    "df_train_events_timestamp_extension = pd.DataFrame(columns=[\"timestamp (hh:mm:ss)\", \"timestamp (seconds/5)\"])\n",
    "\n",
    "# Loop over every test subject\n",
    "# Isn't useful for time conversion, because it is independant of the subject id, but will come in handy in the next steps\n",
    "series_id = pd.unique(df_train_events[\"series_id\"])\n",
    "print(\"Test subjects studied :\", len(series_id), \"unique id\")\n",
    "for serie_id in tqdm(series_id):\n",
    "    \"\"\"\n",
    "    Timestamp conversion into daily elapsed instants (1 instant = 5 seconds)\n",
    "    \"\"\"\n",
    "    # Extracting every sample \"target\" values, for each test subject (serie_id)  \n",
    "    df_train_events_individual = df_train_events[(df_train_events[\"series_id\"] == serie_id)]\n",
    "    \n",
    "    if show_data:\n",
    "        display(df_train_events_individual.head())\n",
    "    \n",
    "    # Extracting the instant of the day when an event happened (dropping the year/month/day)\n",
    "    df_day_time = pd.DataFrame([datetime.strptime(t, \"%Y-%m-%dT%H:%M:%S%z\").time()\n",
    "                                for t in df_train_events_individual[\"timestamp\"].values],\n",
    "                               columns=[\"timestamp (hh:mm:ss)\"])\n",
    "    if show_data:\n",
    "        display(df_day_time.head())\n",
    "    \n",
    "    # Converting the instant in seconds ranging from 00:00:00 to 23:59:59, 5 seconds step (00:00:00, 00:00:05, ...)\n",
    "    midnight = datetime.combine(datetime.today(), time(0, 0, 0))\n",
    "    df_day_time[\"timestamp (seconds/5)\"] = pd.DataFrame([(datetime.combine(datetime.today(), t) - midnight).total_seconds()//5\n",
    "                                                       for t in df_day_time[\"timestamp (hh:mm:ss)\"].values])\n",
    "    if show_data:\n",
    "        display(df_day_time.head())\n",
    "        \n",
    "    # Saving the converted timestamps rows of the current test subject\n",
    "    df_train_events_timestamp_extension = pd.concat([df_train_events_timestamp_extension, df_day_time], \n",
    "                                                    ignore_index=True)\n",
    "\n",
    "# Concatenating the two new seconds columns to the train_events dataframe\n",
    "df_train_events_updated = pd.concat([df_train_events, df_train_events_timestamp_extension], axis=1)\n",
    "\n",
    "\"\"\"\n",
    "Event conversion into targets\n",
    "\"\"\"\n",
    "# \"Onset\" event is labelled as target 0\n",
    "# \"Wakeup\" event is labelled as target 1\n",
    "event_replacement = {'onset': 0, 'wakeup': 1}\n",
    "df_train_events_updated = df_train_events_updated.replace(event_replacement)\n",
    "\n",
    "\"\"\"\n",
    "Dataframe conversion to csv and saving\n",
    "\"\"\"\n",
    "display(df_train_events_updated.head())\n",
    "df_train_events_updated.to_csv(\"train_events_updated.csv\", index=False)\n",
    "print(\"Updated data saved as 'train_events_updated.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5f3d17",
   "metadata": {},
   "source": [
    "#### Submission data structure\n",
    "The submission file should be generated as:\n",
    "- row_id : row number, found in the test_series parquet\n",
    "- series_id : unique identifyer, found in the test_series parquet\n",
    "- step : instant of the event daily-wise, according to the evaluation criteria, should be within [12, 36, 60, 90, 120, 150, 180, 240, 300, 360] steps\n",
    "- event : predicted event, **target should be converted from label to string**\n",
    "- score : confidence score, should return the value of the argmax, ie the probability of the event happening, according to the nn output \n",
    "```python\n",
    "predicted_class = class_probabilities.argmax(dim=1)\n",
    "confidence_scores = class_probabilities.max(dim=1).values  \n",
    "#eg: \n",
    "class_probabilities = [0.03, 0.76, 0.28]\n",
    "predicted_class = 1\n",
    "#Thus, score=0.76 for event=1\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee8ab188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>step</th>\n",
       "      <th>event</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>100</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>105</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>03d92c9f6f8a</td>\n",
       "      <td>80</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>03d92c9f6f8a</td>\n",
       "      <td>110</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0402a003dae9</td>\n",
       "      <td>90</td>\n",
       "      <td>onset</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id     series_id  step   event  score\n",
       "0       0  038441c925bb   100   onset    0.0\n",
       "1       1  038441c925bb   105  wakeup    0.0\n",
       "2       2  03d92c9f6f8a    80   onset    0.5\n",
       "3       3  03d92c9f6f8a   110  wakeup    0.5\n",
       "4       4  0402a003dae9    90   onset    1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample_submission = pd.read_csv(current_folder_path + \"/sample_submission.csv\")\n",
    "df_sample_submission.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1383f947",
   "metadata": {},
   "source": [
    "## Parquet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5651ba18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>step</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>anglez</th>\n",
       "      <th>enmo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-08-14T15:30:00-0400</td>\n",
       "      <td>2.6367</td>\n",
       "      <td>0.0217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-08-14T15:30:05-0400</td>\n",
       "      <td>2.6368</td>\n",
       "      <td>0.0215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-08-14T15:30:10-0400</td>\n",
       "      <td>2.6370</td>\n",
       "      <td>0.0216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-08-14T15:30:15-0400</td>\n",
       "      <td>2.6368</td>\n",
       "      <td>0.0213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-08-14T15:30:20-0400</td>\n",
       "      <td>2.6368</td>\n",
       "      <td>0.0215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      series_id  step                 timestamp  anglez    enmo\n",
       "0  038441c925bb     0  2018-08-14T15:30:00-0400  2.6367  0.0217\n",
       "1  038441c925bb     1  2018-08-14T15:30:05-0400  2.6368  0.0215\n",
       "2  038441c925bb     2  2018-08-14T15:30:10-0400  2.6370  0.0216\n",
       "3  038441c925bb     3  2018-08-14T15:30:15-0400  2.6368  0.0213\n",
       "4  038441c925bb     4  2018-08-14T15:30:20-0400  2.6368  0.0215"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_series = pd.read_parquet(current_folder_path + \"/test_series.parquet\")\n",
    "df_test_series.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3c6b44",
   "metadata": {},
   "source": [
    "#### Parquet to unique serie_id csv\n",
    "Transforms the raw data into sub sets of samples referenced by the unique serie_id number of each test subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a00100d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['series_id', 'step', 'timestamp', 'anglez', 'enmo'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 269/269 [00:00<00:00, 311.20it/s]\n",
      "1953it [54:53,  1.69s/it]3 [54:50<00:00,  2.45s/it] \n",
      "100%|██████████| 1953/1953 [54:53<00:00,  1.69s/it]\n"
<<<<<<< HEAD
=======
     ]
    }
   ],
   "source": [
    "batch_parquet = pq.ParquetFile(current_folder_path + \"/train_series.parquet\")\n",
    "\n",
    "\"\"\"\n",
    "Metadata collection : unique id list and column names\n",
    "\"\"\"\n",
    "series_id = pd.unique(df_train_events[\"series_id\"])\n",
    "for batch in batch_parquet.iter_batches():\n",
    "    df_batch_train_series = batch.to_pandas()\n",
    "    columns = df_batch_train_series.columns\n",
    "    print(columns)\n",
    "    break\n",
    "\n",
    "\"\"\"\n",
    "Generation of datafiles for each test subject (serie_id)\n",
    "\"\"\"\n",
    "if (input(\"Regenerate serie_id csv files ? [y]/n : \") == \"y\"):\n",
    "    for serie_id in tqdm(series_id):\n",
    "        df_train_series = pd.DataFrame([], columns=columns)\n",
    "        df_train_series.to_csv(f\"{current_folder_path}/series_id_data/{serie_id}.csv\")\n",
    "\n",
    "    df_mixed_train_series = pd.DataFrame([], columns=columns)\n",
    "    df_mixed_train_series.to_csv(f\"{current_folder_path}/series_id_data/_mixed_batches.csv\")\n",
    "\n",
    "\"\"\"\n",
    "Sorting data of every test subject (serie_id)\n",
    "\"\"\"\n",
    "# Raw data is stored in a single large parquet file (opened as 1953 batches). \n",
    "# The data has to be opened and divided among the test subjects accordingly\n",
    "if (input(\"Read and write batch files ? [y]/n : \") == \"y\"):\n",
    "    meter = 0\n",
    "    with tqdm(total=1953, initial=0) as pbar: # ~60min\n",
    "        for batch in tqdm(batch_parquet.iter_batches()):\n",
    "            pbar.update(1)  \n",
    "            meter += 1\n",
    "\n",
    "            # Batch itteration\n",
    "            df_current_batch = batch.to_pandas()   \n",
    "            \n",
    "            # series_id featured in the current batch\n",
    "            current_id = pd.unique(df_current_batch[\"series_id\"])\n",
    "\n",
    "            # If the batch refers to only one test subject, it is sent to the according subject csv file\n",
    "            if len(current_id) == 1 and (current_id in series_id):\n",
    "                df_serie_id_csv = pd.read_csv(current_folder_path + f\"/series_id_data/{current_id[0]}.csv\")\n",
    "\n",
    "                # Concatenation of the stored subjct info to the info retreived from the batch\n",
    "                df_serie_id_csv = pd.concat([df_serie_id_csv[columns], df_current_batch[columns]], axis=0)\n",
    "                df_serie_id_csv.to_csv(current_folder_path + f\"/series_id_data/{current_id[0]}.csv\")\n",
    "            \n",
    "            # If the batch features a rupture among the test subjects, it is stored to be sorted later on\n",
    "            else:\n",
    "                #df_mixed_train_series = pd.read_csv(current_folder_path + f\"/series_id_data/_mixed_batches.csv\")\n",
    "                df_mixed_train_series = pd.concat([df_mixed_train_series[columns], df_current_batch[columns]], axis=0)\n",
    "                #df_mixed_train_series.to_csv(f\"{current_folder_path}/series_id_data/_mixed_batches.csv\")\n",
    "\n",
    "    # df_mixed_train_series features mixed data, which will have to be shared among the other serie_id csv files\n",
    "    unclassed_rows = df_mixed_train_series.shape[0]\n",
    "    df_mixed_train_series.to_csv(f\"{current_folder_path}/series_id_data/_mixed_batches.csv\")\n",
    "    print(f\"{meter} batches successfully opened and saved.\") \n",
    "    print(f\"{unclassed_rows} unassigned samples.\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad3015b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['series_id', 'step', 'timestamp', 'anglez', 'enmo'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [20:09<00:00,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intended id to sort : 277 \n",
      " ['038441c925bb' '03d92c9f6f8a' '0402a003dae9' '04f547b8017d'\n",
      " '05e1944c3818' '062cae666e2a' '062dbd4c95e6' '08db4255286f'\n",
      " '0a96f4993bd7' '0cd1e3d0ed95' '0ce74d6d2106' '0cfc06c129cc'\n",
      " '0d0ad1e77851' '0dee4fda51c3' '0ec9fc461819' '0ef7d94fde99'\n",
      " '0f572d690310' '0f9e60a8e56d' '10469f6765bf' '1087d7b0ff2e'\n",
      " '10f8bc1f7b07' '12d01911d509' '1319a1935f48' '137771d19ca2'\n",
      " '137b99e936ab' '13b4d6a01d27' '148471991ffb' '154fe824ed87'\n",
      " '16fe2798ed0f' '1716cd4163b2' '1762ab70ec76' '188d4b7cd28b'\n",
      " '18a0ca03431d' '18b61dd5aae8' '1955d568d987' '1b92be89db4c'\n",
      " '1c7c0bad1263' '1d4569cbac0f' '1e6717d93c1d' '1f96b9668bdf'\n",
      " '207eded97727' '25e2b3dd9c3b' '2654a87be968' '27f09a6a858f'\n",
      " '280e08693c6d' '292a75c0b94e' '29c75c018220' '29d3469bd15d'\n",
      " '2b0a1fa8eba8' '2b8d87addea9' '2cd2340ca14d' '2e9ced2c7976'\n",
      " '2f7504d0f426' '2fbbee1a38e3' '2fc653ca75c7' '31011ade7c0a'\n",
      " '3318a0e3ed6f' '33ceeba8918a' '3452b878e596' '349c5562ee2c'\n",
      " '35826366dfc7' '361366da569e' '3664fe9233f9' '3665c86afaf5'\n",
      " '390b487231ce' '3a9a9dc2cbd9' '3aceb17ef7bd' '3be1545083b7'\n",
      " '3be2f86c3e45' '3c336d6ba566' '3d53bfea61d6' '3df0da2e5966'\n",
      " '405df1b41f9f' '40dce6018935' '416354edd92a' '449766346eb1'\n",
      " '44a41bba1ee7' '44d8c02b369e' '4743bdde25df' '483d6545417f'\n",
      " '4a31811f3558' '4ab54be1a403' '4ac356361be9' '4b45c36f8f5a'\n",
      " '4feda0596965' '519ae2d858b0' '51b23d177971' '51c49c540b4e'\n",
      " '51fdcc8d9fe7' '559ffb7c166a' '55a47ff9dc8a' '55b7f5c99930'\n",
      " '599ca4ed791b' '5aad18e7ce64' '5acc9d63b5fd' '5c088d7e916c'\n",
      " '5c55a5e717d6' '5e816f11f5c3' '5f40907ec171' '5f76965e10cf'\n",
      " '5f94bb3e1bed' '5ffd5e1e81ac' '601559e1777d' '60d31b0bec3b'\n",
      " '60e51cad2ffb' '612aa8ba44e2' '653622ac8363' '655f19eabf1e'\n",
      " '67f5fc60e494' '694faf956ebf' '6a4cd123bd69' '6bf95a3cf91c'\n",
      " '6ca4f4fca6a2' '6d6b9d22d48a' '6ee4ade1f2bd' '702bb5387b1e'\n",
      " '703b5efa9bc1' '72ba4a8afff4' '72bbd1ac3edf' '72d2234e84e4'\n",
      " '73fb772e50fb' '7476c0bd18d2' '7504165f497d' '752900afe3a6'\n",
      " '76237b9406d5' '77ca4db83644' '7822ee8fe3ec' '78569a801a38'\n",
      " '785c9ca4eff7' '7df249527c63' '7fd4284b7ee8' '804594bb1f06'\n",
      " '808652a666c6' '83fa182bec3a' '844f54dcab89' '854206f602d0'\n",
      " '87a6cbb7c4ed' '8877a6586606' '8898e6db816d' '89bd631d1769'\n",
      " '89c7daa72eee' '8a22387617c3' '8a306e0890c0' '8b159a98f485'\n",
      " '8b8b9e29171c' '8becc76ea607' '8e32047cbc1f' '8f6f15b9f598'\n",
      " '8fb18e36697d' '90eac42a9ec9' '91127c2b0e60' '91cb6c98201f'\n",
      " '9277be28a1cf' '927dd0c35dfd' '939932f1822d' '971207c6a525'\n",
      " '99237ce045e4' '99b829cbad2d' '9a340507e36a' '9aed9ee12ae2'\n",
      " '9b9cd7b7af8c' '9c91c546e095' '9ddd40f2cb36' '9ee455e4770d'\n",
      " '9fbdeffbe2ba' 'a167532acca2' 'a261bc4b7470' 'a2b0a64ec9cf'\n",
      " 'a3e59c2ce3f6' 'a4e48102f402' 'a596ad0b82aa' 'a681f9b04b21'\n",
      " 'a81f4472c637' 'a88088855de5' 'a9a2f7fac455' 'a9e5f5314bcb'\n",
      " 'aa81faa78747' 'ad425f3ee76d' 'aed3850f65f0' 'af91d9a50547'\n",
      " 'b1831c4979da' 'b364205aba43' 'b4b75225b224' 'b7188813d58a'\n",
      " 'b737f8c78ec5' 'b750c8c1556c' 'b7fc34995d0f' 'b84960841a75'\n",
      " 'ba8083a2c3b8' 'bb5612895813' 'bccf2f2819f8' 'bdfce9ce62b9'\n",
      " 'bf00506437aa' 'bfa54bd26187' 'bfe41e96d12f' 'c107b5789660'\n",
      " 'c289c8a823e0' 'c3072a759efb' 'c38707ef76df' 'c535634d7dcd'\n",
      " 'c5365a55ebb7' 'c5d08fc3e040' 'c6788e579967' 'c68260cc9e8f'\n",
      " 'c75b4b207bea' 'c7b1283bb7eb' 'c7b2155a4a47' 'c7d693f24684'\n",
      " 'c8053490cec2' 'c908a0ad3e31' 'ca730dbf521d' 'ca732a3c37f7'\n",
      " 'cca14d1966c1' 'ccdee561ee5d' 'ce85771a714c' 'ce9164297046'\n",
      " 'cf13ed7e457a' 'cfeb11428dd7' 'd043c0ca71cd' 'd0f613c700f7'\n",
      " 'd150801f3145' 'd25e479ecbb7' 'd2d6b9af0553' 'd2fef7e4defd'\n",
      " 'd3dddd3c0e00' 'd515236bdeec' 'd5be621fd9aa' 'd5e47b94477e'\n",
      " 'd8de352c2657' 'd93b0c7de16b' 'd9e887091a5c' 'dacc6d652e35'\n",
      " 'db5e0ee1c0ab' 'db75092f0530' 'dc80ca623d71' 'de6fedfb6139'\n",
      " 'def21f50dd3c' 'df33ae359fb5' 'dfc3ccebfdc9' 'dff367373725'\n",
      " 'e0686434d029' 'e0d7b0dcf9f3' 'e11b9d69f856' 'e1f2a4f991cb'\n",
      " 'e1f5abb82285' 'e2a849d283c0' 'e2b60820c325' 'e30cb792a2bc'\n",
      " 'e34b496b84ce' 'e4500e7e19e1' 'e586cbfa7762' 'e69aff66e0cb'\n",
      " 'e6ddbaaf0639' 'e867b5133665' 'e8d0a37c3eba' 'ea0770830757'\n",
      " 'ebb6fae8ed43' 'ebd76e93ec7d' 'ece2561f07e9' 'ee4e0e3afd3d'\n",
      " 'eec197a4bdca' 'eef041dd50aa' 'efbfc4526d58' 'f0482490923c'\n",
      " 'f2c2436cf7b7' 'f564985ab692' 'f56824b503a0' 'f6d2cc003183'\n",
      " 'f7eb179216c2' 'f88e18cb4100' 'f8a8da8bdd00' 'f981a0805fd0'\n",
      " 'fa149c3c4bde' 'fb223ed2278c' 'fbf33b1a2c10' 'fcca183903b7'\n",
      " 'fe90110788d2']\n",
      "Failed id to sort : 8 \n",
      " ['0f9e60a8e56d', '2fc653ca75c7', '390b487231ce', '89c7daa72eee', 'a3e59c2ce3f6', 'c5d08fc3e040', 'c7b1283bb7eb', 'e11b9d69f856']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_mixed_train_series = pd.read_csv(f\"{current_folder_path}/series_id_data/_mixed_batches.csv\", index_col=0)\n",
    "columns = df_mixed_train_series.columns\n",
    "print(columns)\n",
    "\n",
    "unclassed_series_id = pd.unique(df_mixed_train_series[\"series_id\"])\n",
    "list_failed_to_sort = []\n",
    "for unclassed_serie_id in tqdm(unclassed_series_id): # ~20min\n",
    "    df_unclassed_train_series = df_mixed_train_series[(df_mixed_train_series[\"series_id\"] == unclassed_serie_id)][columns]\n",
    "    try:\n",
    "        df_serie_id_csv = pd.read_csv(f\"{current_folder_path}/series_id_data/{unclassed_serie_id}.csv\")\n",
    "        df_serie_id_csv = pd.concat([df_serie_id_csv[columns], df_unclassed_train_series[columns]])\n",
    "        df_serie_id_csv.to_csv(f\"{current_folder_path}/series_id_data/{unclassed_serie_id}.csv\")\n",
    "    except:\n",
    "        list_failed_to_sort.append(unclassed_serie_id)\n",
    "        \"\"\"\n",
    "            df_serie_id_csv = pd.DataFrame([], columns=columns)\n",
    "            df_serie_id_csv = pd.concat([df_serie_id_csv[columns], df_unclassed_train_series[columns]])\n",
    "            df_serie_id_csv.to_csv(f\"{current_folder_path}/series_id_data/{unclassed_serie_id}.csv\")        \n",
    "        \"\"\"\n",
    "\n",
    "print(f\"Intended id to sort : {len(unclassed_series_id)}\")\n",
    "print(f\"Failed id to sort : {len(list_failed_to_sort)} \\n\", list_failed_to_sort)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6904d2",
   "metadata": {},
   "source": [
    "## CSV to features data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57259651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269\n"
     ]
    }
   ],
   "source": [
    "#csv_list = os.path.join(current_folder_path, \"User/Desktop\", \"file.txt\")\n",
    "\n",
    "csv_list = [f for f in os.listdir(current_folder_path + \"/series_id_data/\") if f.endswith(\".csv\")]\n",
    "print(len(csv_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4ee2ae8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 98/269 [01:47<03:54,  1.37s/it]"
>>>>>>> 2-data-merge
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "batch_parquet = pq.ParquetFile(current_folder_path + \"/train_series.parquet\")\n",
    "\n",
    "\"\"\"\n",
    "Metadata collection : unique id list and column names\n",
    "\"\"\"\n",
    "series_id = pd.unique(df_train_events[\"series_id\"])\n",
    "for batch in batch_parquet.iter_batches():\n",
    "    df_batch_train_series = batch.to_pandas()\n",
    "    columns = df_batch_train_series.columns\n",
    "    print(columns)\n",
    "    break\n",
    "\n",
    "\"\"\"\n",
    "Generation of datafiles for each test subject (serie_id)\n",
    "\"\"\"\n",
    "if (input(\"Regenerate serie_id csv files ? [y]/n : \") == \"y\"):\n",
    "    for serie_id in tqdm(series_id):\n",
    "        df_train_series = pd.DataFrame([], columns=columns)\n",
    "        df_train_series.to_csv(f\"{current_folder_path}/series_id_data/{serie_id}.csv\")\n",
    "\n",
    "    df_mixed_train_series = pd.DataFrame([], columns=columns)\n",
    "    df_mixed_train_series.to_csv(f\"{current_folder_path}/series_id_data/_mixed_batches.csv\")\n",
    "\n",
    "\"\"\"\n",
    "Sorting data of every test subject (serie_id)\n",
    "\"\"\"\n",
    "# Raw data is stored in a single large parquet file (opened as 1953 batches). \n",
    "# The data has to be opened and divided among the test subjects accordingly\n",
    "if (input(\"Read and write batch files ? [y]/n : \") == \"y\"):\n",
    "    meter = 0\n",
    "    with tqdm(total=1953, initial=0) as pbar: # ~60min\n",
    "        for batch in tqdm(batch_parquet.iter_batches()):\n",
    "            pbar.update(1)  \n",
    "            meter += 1\n",
    "\n",
    "            # Batch itteration\n",
    "            df_current_batch = batch.to_pandas()   \n",
    "            \n",
    "            # series_id featured in the current batch\n",
    "            current_id = pd.unique(df_current_batch[\"series_id\"])\n",
    "\n",
    "            # If the batch refers to only one test subject, it is sent to the according subject csv file\n",
    "            if len(current_id) == 1 and (current_id in series_id):\n",
    "                df_serie_id_csv = pd.read_csv(current_folder_path + f\"/series_id_data/{current_id[0]}.csv\")\n",
    "\n",
    "                # Concatenation of the stored subjct info to the info retreived from the batch\n",
    "                df_serie_id_csv = pd.concat([df_serie_id_csv[columns], df_current_batch[columns]], axis=0)\n",
    "                df_serie_id_csv.to_csv(current_folder_path + f\"/series_id_data/{current_id[0]}.csv\")\n",
    "            \n",
    "            # If the batch features a rupture among the test subjects, it is stored to be sorted later on\n",
    "            else:\n",
    "                #df_mixed_train_series = pd.read_csv(current_folder_path + f\"/series_id_data/_mixed_batches.csv\")\n",
    "                df_mixed_train_series = pd.concat([df_mixed_train_series[columns], df_current_batch[columns]], axis=0)\n",
    "                #df_mixed_train_series.to_csv(f\"{current_folder_path}/series_id_data/_mixed_batches.csv\")\n",
    "\n",
    "    # df_mixed_train_series features mixed data, which will have to be shared among the other serie_id csv files\n",
    "    unclassed_rows = df_mixed_train_series.shape[0]\n",
    "    df_mixed_train_series.to_csv(f\"{current_folder_path}/series_id_data/_mixed_batches.csv\")\n",
    "    print(f\"{meter} batches successfully opened and saved.\") \n",
    "    print(f\"{unclassed_rows} unassigned samples.\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad3015b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['series_id', 'step', 'timestamp', 'anglez', 'enmo'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [20:09<00:00,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intended id to sort : 277 \n",
      " ['038441c925bb' '03d92c9f6f8a' '0402a003dae9' '04f547b8017d'\n",
      " '05e1944c3818' '062cae666e2a' '062dbd4c95e6' '08db4255286f'\n",
      " '0a96f4993bd7' '0cd1e3d0ed95' '0ce74d6d2106' '0cfc06c129cc'\n",
      " '0d0ad1e77851' '0dee4fda51c3' '0ec9fc461819' '0ef7d94fde99'\n",
      " '0f572d690310' '0f9e60a8e56d' '10469f6765bf' '1087d7b0ff2e'\n",
      " '10f8bc1f7b07' '12d01911d509' '1319a1935f48' '137771d19ca2'\n",
      " '137b99e936ab' '13b4d6a01d27' '148471991ffb' '154fe824ed87'\n",
      " '16fe2798ed0f' '1716cd4163b2' '1762ab70ec76' '188d4b7cd28b'\n",
      " '18a0ca03431d' '18b61dd5aae8' '1955d568d987' '1b92be89db4c'\n",
      " '1c7c0bad1263' '1d4569cbac0f' '1e6717d93c1d' '1f96b9668bdf'\n",
      " '207eded97727' '25e2b3dd9c3b' '2654a87be968' '27f09a6a858f'\n",
      " '280e08693c6d' '292a75c0b94e' '29c75c018220' '29d3469bd15d'\n",
      " '2b0a1fa8eba8' '2b8d87addea9' '2cd2340ca14d' '2e9ced2c7976'\n",
      " '2f7504d0f426' '2fbbee1a38e3' '2fc653ca75c7' '31011ade7c0a'\n",
      " '3318a0e3ed6f' '33ceeba8918a' '3452b878e596' '349c5562ee2c'\n",
      " '35826366dfc7' '361366da569e' '3664fe9233f9' '3665c86afaf5'\n",
      " '390b487231ce' '3a9a9dc2cbd9' '3aceb17ef7bd' '3be1545083b7'\n",
      " '3be2f86c3e45' '3c336d6ba566' '3d53bfea61d6' '3df0da2e5966'\n",
      " '405df1b41f9f' '40dce6018935' '416354edd92a' '449766346eb1'\n",
      " '44a41bba1ee7' '44d8c02b369e' '4743bdde25df' '483d6545417f'\n",
      " '4a31811f3558' '4ab54be1a403' '4ac356361be9' '4b45c36f8f5a'\n",
      " '4feda0596965' '519ae2d858b0' '51b23d177971' '51c49c540b4e'\n",
      " '51fdcc8d9fe7' '559ffb7c166a' '55a47ff9dc8a' '55b7f5c99930'\n",
      " '599ca4ed791b' '5aad18e7ce64' '5acc9d63b5fd' '5c088d7e916c'\n",
      " '5c55a5e717d6' '5e816f11f5c3' '5f40907ec171' '5f76965e10cf'\n",
      " '5f94bb3e1bed' '5ffd5e1e81ac' '601559e1777d' '60d31b0bec3b'\n",
      " '60e51cad2ffb' '612aa8ba44e2' '653622ac8363' '655f19eabf1e'\n",
      " '67f5fc60e494' '694faf956ebf' '6a4cd123bd69' '6bf95a3cf91c'\n",
      " '6ca4f4fca6a2' '6d6b9d22d48a' '6ee4ade1f2bd' '702bb5387b1e'\n",
      " '703b5efa9bc1' '72ba4a8afff4' '72bbd1ac3edf' '72d2234e84e4'\n",
      " '73fb772e50fb' '7476c0bd18d2' '7504165f497d' '752900afe3a6'\n",
      " '76237b9406d5' '77ca4db83644' '7822ee8fe3ec' '78569a801a38'\n",
      " '785c9ca4eff7' '7df249527c63' '7fd4284b7ee8' '804594bb1f06'\n",
      " '808652a666c6' '83fa182bec3a' '844f54dcab89' '854206f602d0'\n",
      " '87a6cbb7c4ed' '8877a6586606' '8898e6db816d' '89bd631d1769'\n",
      " '89c7daa72eee' '8a22387617c3' '8a306e0890c0' '8b159a98f485'\n",
      " '8b8b9e29171c' '8becc76ea607' '8e32047cbc1f' '8f6f15b9f598'\n",
      " '8fb18e36697d' '90eac42a9ec9' '91127c2b0e60' '91cb6c98201f'\n",
      " '9277be28a1cf' '927dd0c35dfd' '939932f1822d' '971207c6a525'\n",
      " '99237ce045e4' '99b829cbad2d' '9a340507e36a' '9aed9ee12ae2'\n",
      " '9b9cd7b7af8c' '9c91c546e095' '9ddd40f2cb36' '9ee455e4770d'\n",
      " '9fbdeffbe2ba' 'a167532acca2' 'a261bc4b7470' 'a2b0a64ec9cf'\n",
      " 'a3e59c2ce3f6' 'a4e48102f402' 'a596ad0b82aa' 'a681f9b04b21'\n",
      " 'a81f4472c637' 'a88088855de5' 'a9a2f7fac455' 'a9e5f5314bcb'\n",
      " 'aa81faa78747' 'ad425f3ee76d' 'aed3850f65f0' 'af91d9a50547'\n",
      " 'b1831c4979da' 'b364205aba43' 'b4b75225b224' 'b7188813d58a'\n",
      " 'b737f8c78ec5' 'b750c8c1556c' 'b7fc34995d0f' 'b84960841a75'\n",
      " 'ba8083a2c3b8' 'bb5612895813' 'bccf2f2819f8' 'bdfce9ce62b9'\n",
      " 'bf00506437aa' 'bfa54bd26187' 'bfe41e96d12f' 'c107b5789660'\n",
      " 'c289c8a823e0' 'c3072a759efb' 'c38707ef76df' 'c535634d7dcd'\n",
      " 'c5365a55ebb7' 'c5d08fc3e040' 'c6788e579967' 'c68260cc9e8f'\n",
      " 'c75b4b207bea' 'c7b1283bb7eb' 'c7b2155a4a47' 'c7d693f24684'\n",
      " 'c8053490cec2' 'c908a0ad3e31' 'ca730dbf521d' 'ca732a3c37f7'\n",
      " 'cca14d1966c1' 'ccdee561ee5d' 'ce85771a714c' 'ce9164297046'\n",
      " 'cf13ed7e457a' 'cfeb11428dd7' 'd043c0ca71cd' 'd0f613c700f7'\n",
      " 'd150801f3145' 'd25e479ecbb7' 'd2d6b9af0553' 'd2fef7e4defd'\n",
      " 'd3dddd3c0e00' 'd515236bdeec' 'd5be621fd9aa' 'd5e47b94477e'\n",
      " 'd8de352c2657' 'd93b0c7de16b' 'd9e887091a5c' 'dacc6d652e35'\n",
      " 'db5e0ee1c0ab' 'db75092f0530' 'dc80ca623d71' 'de6fedfb6139'\n",
      " 'def21f50dd3c' 'df33ae359fb5' 'dfc3ccebfdc9' 'dff367373725'\n",
      " 'e0686434d029' 'e0d7b0dcf9f3' 'e11b9d69f856' 'e1f2a4f991cb'\n",
      " 'e1f5abb82285' 'e2a849d283c0' 'e2b60820c325' 'e30cb792a2bc'\n",
      " 'e34b496b84ce' 'e4500e7e19e1' 'e586cbfa7762' 'e69aff66e0cb'\n",
      " 'e6ddbaaf0639' 'e867b5133665' 'e8d0a37c3eba' 'ea0770830757'\n",
      " 'ebb6fae8ed43' 'ebd76e93ec7d' 'ece2561f07e9' 'ee4e0e3afd3d'\n",
      " 'eec197a4bdca' 'eef041dd50aa' 'efbfc4526d58' 'f0482490923c'\n",
      " 'f2c2436cf7b7' 'f564985ab692' 'f56824b503a0' 'f6d2cc003183'\n",
      " 'f7eb179216c2' 'f88e18cb4100' 'f8a8da8bdd00' 'f981a0805fd0'\n",
      " 'fa149c3c4bde' 'fb223ed2278c' 'fbf33b1a2c10' 'fcca183903b7'\n",
      " 'fe90110788d2']\n",
      "Failed id to sort : 8 \n",
      " ['0f9e60a8e56d', '2fc653ca75c7', '390b487231ce', '89c7daa72eee', 'a3e59c2ce3f6', 'c5d08fc3e040', 'c7b1283bb7eb', 'e11b9d69f856']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_mixed_train_series = pd.read_csv(f\"{current_folder_path}/series_id_data/_mixed_batches.csv\", index_col=0)\n",
    "columns = df_mixed_train_series.columns\n",
    "print(columns)\n",
    "\n",
    "unclassed_series_id = pd.unique(df_mixed_train_series[\"series_id\"])\n",
    "list_failed_to_sort = []\n",
    "for unclassed_serie_id in tqdm(unclassed_series_id): # ~20min\n",
    "    df_unclassed_train_series = df_mixed_train_series[(df_mixed_train_series[\"series_id\"] == unclassed_serie_id)][columns]\n",
    "    try:\n",
    "        df_serie_id_csv = pd.read_csv(f\"{current_folder_path}/series_id_data/{unclassed_serie_id}.csv\")\n",
    "        df_serie_id_csv = pd.concat([df_serie_id_csv[columns], df_unclassed_train_series[columns]])\n",
    "        df_serie_id_csv.to_csv(f\"{current_folder_path}/series_id_data/{unclassed_serie_id}.csv\")\n",
    "    except:\n",
    "        list_failed_to_sort.append(unclassed_serie_id)\n",
    "        \"\"\"\n",
    "            df_serie_id_csv = pd.DataFrame([], columns=columns)\n",
    "            df_serie_id_csv = pd.concat([df_serie_id_csv[columns], df_unclassed_train_series[columns]])\n",
    "            df_serie_id_csv.to_csv(f\"{current_folder_path}/series_id_data/{unclassed_serie_id}.csv\")        \n",
    "        \"\"\"\n",
    "\n",
    "print(f\"Intended id to sort : {len(unclassed_series_id)}\")\n",
    "print(f\"Failed id to sort : {len(list_failed_to_sort)} \\n\", list_failed_to_sort)\n"
=======
    "df_train_events = pd.read_csv(current_folder_path + \"/train_events_updated.csv\").dropna()\n",
    "\n",
    "\n",
    "df_features = pd.DataFrame([], columns=[\"anglez\", \"enmo\"])\n",
    "df_targets = pd.DataFrame([], columns=[\"event\"])\n",
    "columns = df_features.columns\n",
    "\n",
    "array = np.zeros((1, 1 + 721*2 + 2))\n",
    "for serie_id in tqdm(csv_list):\n",
    "\n",
    "    # Dataframe containing all the event data\n",
    "    df_indexes = df_train_events[df_train_events[\"series_id\"]==serie_id[:-4]][[\"event\", \"step\", \"timestamp (seconds/5)\"]]\n",
    "    df_steps = df_indexes[[\"step\"]]\n",
    "\n",
    "    # Dataframe containing all the sample data\n",
    "    df_samples = pd.read_csv(f\"{current_folder_path}/series_id_data/{serie_id}\", index_col=0)\n",
    "\n",
    "    #print(df_indexes.shape, df_samples.shape)\n",
    "\n",
    "    for step in df_steps.values:\n",
    "        # Only the data within 30min of an event is gathered \n",
    "        sample_data = df_samples[df_samples[\"step\"].between(step[0]-360, step[0]+360)]\n",
    "\n",
    "        # The index time-wise of the event\n",
    "        event_data = df_indexes[df_indexes[\"step\"] == step[0]]\n",
    "\n",
    "        # Data is converted as a flattened array\n",
    "        anglez = sample_data[\"anglez\"].to_numpy()\n",
    "        enmo = sample_data[\"enmo\"].to_numpy()\n",
    "\n",
    "        timestamp = event_data[\"timestamp (seconds/5)\"].to_numpy()\n",
    "        event = event_data[\"event\"].to_numpy()\n",
    "\n",
    "        # The array shape is 1 + 721*2 + 1 + 1 = 1445 \n",
    "        array_step = np.array([np.concatenate((step, anglez.T, enmo.T, timestamp, event))])\n",
    "        #print(array_step.shape, array.shape)\n",
    "        try:\n",
    "            array = np.concatenate((array, array_step), axis=0)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "np.save(f\"{current_folder_path}/data.npy\", array)\n",
    "\n",
    "print(array.shape)"
>>>>>>> 2-data-merge
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "57259651",
=======
   "id": "6757c2cd",
>>>>>>> 2-data-merge
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
