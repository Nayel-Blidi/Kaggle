{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5300a851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "from datetime import datetime, time\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "current_folder_path = os.path.abspath('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f4dad1",
   "metadata": {},
   "source": [
    "## CSV data\n",
    "#### Train events\n",
    "Contains the target data, ie the *starting to sleep* and *waking up* events.\n",
    "- **series_id** : unique subject id, primary key when linked to the **train_series** parquet data  \n",
    "- **night** : counts the nth night of the serie  \n",
    "- **event** : target of the studie, with to values : *onset* and *wakeup*  \n",
    "- **step**: gives the index sample data corresponding to the event in the of the **train_series** parquet data. When multiplied by 5, gives the equivalent lasted time since the begining of the studie on the current test subject.  \n",
    "- **timestamp** : datetime object, exact time of the event, presented in the form of yyyy-mm-ddThh-mm-ss-utc\n",
    "\n",
    "#### Sample submission\n",
    "An example of the format in which the aswer data should be submitted to be evaluated\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 28,
>>>>>>> 5634803f820c05e4168f4dc3243aba6f96fddf71
   "id": "226de7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>night</th>\n",
       "      <th>event</th>\n",
       "      <th>step</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>1</td>\n",
       "      <td>onset</td>\n",
       "      <td>4992.0</td>\n",
       "      <td>2018-08-14T22:26:00-0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>1</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>10932.0</td>\n",
       "      <td>2018-08-15T06:41:00-0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>2</td>\n",
       "      <td>onset</td>\n",
       "      <td>20244.0</td>\n",
       "      <td>2018-08-15T19:37:00-0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>2</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>27492.0</td>\n",
       "      <td>2018-08-16T05:41:00-0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>3</td>\n",
       "      <td>onset</td>\n",
       "      <td>39996.0</td>\n",
       "      <td>2018-08-16T23:03:00-0400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      series_id  night   event     step                 timestamp\n",
       "0  038441c925bb      1   onset   4992.0  2018-08-14T22:26:00-0400\n",
       "1  038441c925bb      1  wakeup  10932.0  2018-08-15T06:41:00-0400\n",
       "2  038441c925bb      2   onset  20244.0  2018-08-15T19:37:00-0400\n",
       "3  038441c925bb      2  wakeup  27492.0  2018-08-16T05:41:00-0400\n",
       "4  038441c925bb      3   onset  39996.0  2018-08-16T23:03:00-0400"
      ]
     },
<<<<<<< HEAD
     "execution_count": 3,
=======
     "execution_count": 28,
>>>>>>> 5634803f820c05e4168f4dc3243aba6f96fddf71
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_events = pd.read_csv(current_folder_path + \"/train_events.csv\").dropna()\n",
    "df_train_events.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42f0a00",
   "metadata": {},
   "source": [
    "#### Timestamp conversion\n",
    "The timestamps are converted to instant of the day, as the date doesn't matter when sstudying daily events such as going to bed and waking up.\n",
    "Thus, the timestamps of every sleeping events, for every test subject (series_id) are converted in seconds//5.\n",
    "To get the time in hour format, the following retreiving operation can easily be computed :\n",
    "```python\n",
    "real_seconds = seconds * 5 \n",
    "h = real_seconds // 3600\n",
    "m = (real_seconds - h*3600) // 60\n",
    "s = (real_seconds - h*3600 - m*60)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 29,
>>>>>>> 5634803f820c05e4168f4dc3243aba6f96fddf71
   "id": "785191ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:1:1\n"
     ]
    }
   ],
   "source": [
    "#Eg: 01:01:01 ie, 720*5 + 12*5 + 0.2*5 = 3600 + 60 + 1 = 1h + 1m + 1s\n",
    "\n",
    "seconds = 720 + 12 + 0.2\n",
    "real_seconds = seconds * 5 \n",
    "h = round(real_seconds // 3600)\n",
    "m = round((real_seconds - h*3600) // 60)\n",
    "s = round(real_seconds - h*3600 - m*60)\n",
    "\n",
    "print(f\"{h}:{m}:{s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c2be7f",
   "metadata": {},
   "source": [
    "## Target data editing"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 30,
>>>>>>> 5634803f820c05e4168f4dc3243aba6f96fddf71
   "id": "748d77e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test subjects studied : 269 unique id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "100%|██████████| 269/269 [00:01<00:00, 179.56it/s]\n"
=======
      "100%|██████████| 269/269 [00:00<00:00, 430.24it/s]\n"
>>>>>>> 5634803f820c05e4168f4dc3243aba6f96fddf71
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>night</th>\n",
       "      <th>event</th>\n",
       "      <th>step</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>timestamp (hh:mm:ss)</th>\n",
       "      <th>timestamp (seconds/5)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4992.0</td>\n",
       "      <td>2018-08-14T22:26:00-0400</td>\n",
       "      <td>22:26:00</td>\n",
       "      <td>16152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10932.0</td>\n",
       "      <td>2018-08-15T06:41:00-0400</td>\n",
       "      <td>06:41:00</td>\n",
       "      <td>4812.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20244.0</td>\n",
       "      <td>2018-08-15T19:37:00-0400</td>\n",
       "      <td>19:37:00</td>\n",
       "      <td>14124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27492.0</td>\n",
       "      <td>2018-08-16T05:41:00-0400</td>\n",
       "      <td>05:41:00</td>\n",
       "      <td>4092.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39996.0</td>\n",
       "      <td>2018-08-16T23:03:00-0400</td>\n",
       "      <td>23:03:00</td>\n",
       "      <td>16596.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      series_id  night  event     step                 timestamp  \\\n",
       "0  038441c925bb    1.0    0.0   4992.0  2018-08-14T22:26:00-0400   \n",
       "1  038441c925bb    1.0    1.0  10932.0  2018-08-15T06:41:00-0400   \n",
       "2  038441c925bb    2.0    0.0  20244.0  2018-08-15T19:37:00-0400   \n",
       "3  038441c925bb    2.0    1.0  27492.0  2018-08-16T05:41:00-0400   \n",
       "4  038441c925bb    3.0    0.0  39996.0  2018-08-16T23:03:00-0400   \n",
       "\n",
       "  timestamp (hh:mm:ss)  timestamp (seconds/5)  \n",
       "0             22:26:00                16152.0  \n",
       "1             06:41:00                 4812.0  \n",
       "2             19:37:00                14124.0  \n",
       "3             05:41:00                 4092.0  \n",
       "4             23:03:00                16596.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated data saved as 'train_events_updated.csv'\n"
     ]
    }
   ],
   "source": [
    "show_data = 0\n",
    "\n",
    "# Converted timestamps storing df init\n",
    "df_train_events_timestamp_extension = pd.DataFrame(columns=[\"timestamp (hh:mm:ss)\", \"timestamp (seconds/5)\"])\n",
    "\n",
    "# Loop over every test subject\n",
    "# Isn't useful for time conversion, because it is independant of the subject id, but will come in handy in the next steps\n",
    "series_id = pd.unique(df_train_events[\"series_id\"])\n",
    "print(\"Test subjects studied :\", len(series_id), \"unique id\")\n",
    "for serie_id in tqdm(series_id):\n",
    "    \"\"\"\n",
    "    Timestamp conversion into daily elapsed instants (1 instant = 5 seconds)\n",
    "    \"\"\"\n",
    "    # Extracting every sample \"target\" values, for each test subject (serie_id)  \n",
    "    df_train_events_individual = df_train_events[(df_train_events[\"series_id\"] == serie_id)]\n",
    "    \n",
    "    if show_data:\n",
    "        display(df_train_events_individual.head())\n",
    "    \n",
    "    # Extracting the instant of the day when an event happened (dropping the year/month/day)\n",
    "    df_day_time = pd.DataFrame([datetime.strptime(t, \"%Y-%m-%dT%H:%M:%S%z\").time()\n",
    "                                for t in df_train_events_individual[\"timestamp\"].values],\n",
    "                               columns=[\"timestamp (hh:mm:ss)\"])\n",
    "    if show_data:\n",
    "        display(df_day_time.head())\n",
    "    \n",
    "    # Converting the instant in seconds ranging from 00:00:00 to 23:59:59, 5 seconds step (00:00:00, 00:00:05, ...)\n",
    "    midnight = datetime.combine(datetime.today(), time(0, 0, 0))\n",
    "    df_day_time[\"timestamp (seconds/5)\"] = pd.DataFrame([(datetime.combine(datetime.today(), t) - midnight).total_seconds()//5\n",
    "                                                       for t in df_day_time[\"timestamp (hh:mm:ss)\"].values])\n",
    "    if show_data:\n",
    "        display(df_day_time.head())\n",
    "        \n",
    "    # Saving the converted timestamps rows of the current test subject\n",
    "    df_train_events_timestamp_extension = pd.concat([df_train_events_timestamp_extension, df_day_time], \n",
    "                                                    ignore_index=True)\n",
    "\n",
    "# Concatenating the two new seconds columns to the train_events dataframe\n",
    "df_train_events_updated = pd.concat([df_train_events, df_train_events_timestamp_extension], axis=1)\n",
    "\n",
    "\"\"\"\n",
    "Event conversion into targets\n",
    "\"\"\"\n",
    "# \"Onset\" event is labelled as target 0\n",
    "# \"Wakeup\" event is labelled as target 1\n",
    "event_replacement = {'onset': 0, 'wakeup': 1}\n",
    "df_train_events_updated = df_train_events_updated.replace(event_replacement)\n",
    "\n",
    "\"\"\"\n",
    "Dataframe conversion to csv and saving\n",
    "\"\"\"\n",
    "display(df_train_events_updated.head())\n",
    "df_train_events_updated.to_csv(\"train_events_updated.csv\", index=False)\n",
    "print(\"Updated data saved as 'train_events_updated.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5f3d17",
   "metadata": {},
   "source": [
    "#### Submission data structure\n",
    "The submission file should be generated as:\n",
    "- row_id : row number, found in the test_series parquet\n",
    "- series_id : unique identifyer, found in the test_series parquet\n",
    "- step : instant of the event daily-wise, according to the evaluation criteria, should be within [12, 36, 60, 90, 120, 150, 180, 240, 300, 360] steps\n",
    "- event : predicted event, **target should be converted from label to string**\n",
    "- score : confidence score, should return the value of the argmax, ie the probability of the event happening, according to the nn output \n",
    "```python\n",
    "predicted_class = class_probabilities.argmax(dim=1)\n",
    "confidence_scores = class_probabilities.max(dim=1).values  \n",
    "#eg: \n",
    "class_probabilities = [0.03, 0.76, 0.28]\n",
    "predicted_class = 1\n",
    "#Thus, score=0.76 for event=1\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 31,
>>>>>>> 5634803f820c05e4168f4dc3243aba6f96fddf71
   "id": "ee8ab188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>step</th>\n",
       "      <th>event</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>100</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>105</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>03d92c9f6f8a</td>\n",
       "      <td>80</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>03d92c9f6f8a</td>\n",
       "      <td>110</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0402a003dae9</td>\n",
       "      <td>90</td>\n",
       "      <td>onset</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id     series_id  step   event  score\n",
       "0       0  038441c925bb   100   onset    0.0\n",
       "1       1  038441c925bb   105  wakeup    0.0\n",
       "2       2  03d92c9f6f8a    80   onset    0.5\n",
       "3       3  03d92c9f6f8a   110  wakeup    0.5\n",
       "4       4  0402a003dae9    90   onset    1.0"
      ]
     },
<<<<<<< HEAD
     "execution_count": 9,
=======
     "execution_count": 31,
>>>>>>> 5634803f820c05e4168f4dc3243aba6f96fddf71
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample_submission = pd.read_csv(current_folder_path + \"/sample_submission.csv\")\n",
    "df_sample_submission.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1383f947",
   "metadata": {},
   "source": [
    "## Parquet data"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 32,
>>>>>>> 5634803f820c05e4168f4dc3243aba6f96fddf71
   "id": "5651ba18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>step</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>anglez</th>\n",
       "      <th>enmo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-08-14T15:30:00-0400</td>\n",
       "      <td>2.6367</td>\n",
       "      <td>0.0217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-08-14T15:30:05-0400</td>\n",
       "      <td>2.6368</td>\n",
       "      <td>0.0215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-08-14T15:30:10-0400</td>\n",
       "      <td>2.6370</td>\n",
       "      <td>0.0216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-08-14T15:30:15-0400</td>\n",
       "      <td>2.6368</td>\n",
       "      <td>0.0213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-08-14T15:30:20-0400</td>\n",
       "      <td>2.6368</td>\n",
       "      <td>0.0215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      series_id  step                 timestamp  anglez    enmo\n",
       "0  038441c925bb     0  2018-08-14T15:30:00-0400  2.6367  0.0217\n",
       "1  038441c925bb     1  2018-08-14T15:30:05-0400  2.6368  0.0215\n",
       "2  038441c925bb     2  2018-08-14T15:30:10-0400  2.6370  0.0216\n",
       "3  038441c925bb     3  2018-08-14T15:30:15-0400  2.6368  0.0213\n",
       "4  038441c925bb     4  2018-08-14T15:30:20-0400  2.6368  0.0215"
      ]
     },
<<<<<<< HEAD
     "execution_count": 10,
=======
     "execution_count": 32,
>>>>>>> 5634803f820c05e4168f4dc3243aba6f96fddf71
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_series = pd.read_parquet(current_folder_path + \"/test_series.parquet\")\n",
    "df_test_series.head()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 35,
>>>>>>> 5634803f820c05e4168f4dc3243aba6f96fddf71
   "id": "248828e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>step</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>anglez</th>\n",
       "      <th>enmo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-08-14T15:30:00-0400</td>\n",
       "      <td>2.6367</td>\n",
       "      <td>0.0217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      series_id  step                 timestamp  anglez    enmo\n",
       "0  038441c925bb     0  2018-08-14T15:30:00-0400  2.6367  0.0217"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>step</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>anglez</th>\n",
       "      <th>enmo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65535</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>65535</td>\n",
       "      <td>2018-08-18T10:31:15-0400</td>\n",
       "      <td>4.4599</td>\n",
       "      <td>0.0169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          series_id   step                 timestamp  anglez    enmo\n",
       "65535  038441c925bb  65535  2018-08-18T10:31:15-0400  4.4599  0.0169"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65536, 5)\n",
      "['038441c925bb']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>step</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>anglez</th>\n",
       "      <th>enmo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>65536</td>\n",
       "      <td>2018-08-18T10:31:20-0400</td>\n",
       "      <td>4.1057</td>\n",
       "      <td>0.0172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      series_id   step                 timestamp  anglez    enmo\n",
       "0  038441c925bb  65536  2018-08-18T10:31:20-0400  4.1057  0.0172"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>step</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>anglez</th>\n",
       "      <th>enmo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65535</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>131071</td>\n",
       "      <td>2018-08-22T05:32:35-0400</td>\n",
       "      <td>-7.7837</td>\n",
       "      <td>0.0183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          series_id    step                 timestamp  anglez    enmo\n",
       "65535  038441c925bb  131071  2018-08-22T05:32:35-0400 -7.7837  0.0183"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65536, 5)\n",
      "['038441c925bb']\n",
<<<<<<< HEAD
      "<pyarrow._parquet.FileMetaData object at 0x000002D82A39FAB0>\n",
=======
      "<pyarrow._parquet.FileMetaData object at 0x00000280550BAF90>\n",
>>>>>>> 5634803f820c05e4168f4dc3243aba6f96fddf71
      "  created_by: Arrow2 - Native Rust implementation of Arrow\n",
      "  num_columns: 5\n",
      "  num_rows: 127946340\n",
      "  num_row_groups: 488\n",
      "  format_version: 2.6\n",
      "  serialized_size: 143859\n"
     ]
    }
   ],
   "source": [
    "batch_parquet = pq.ParquetFile(current_folder_path + \"/train_series.parquet\")\n",
    "\n",
    "c=0\n",
    "for batch in batch_parquet.iter_batches():\n",
    "    c+=1\n",
    "    df_batch_train_series = batch.to_pandas()\n",
    "    display(df_batch_train_series.head(1))\n",
    "    display(df_batch_train_series.tail(1))\n",
    "    print(df_batch_train_series.shape)\n",
    "    print(pd.unique(df_batch_train_series[\"series_id\"]))\n",
    "    \n",
    "    #condition = \n",
    "    #target_array = \n",
    "    \n",
    "    if c>=2:\n",
    "        break\n",
    "\n",
    "print(batch_parquet.metadata)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 63,
>>>>>>> 5634803f820c05e4168f4dc3243aba6f96fddf71
   "id": "1a00100d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['series_id', 'step', 'timestamp', 'anglez', 'enmo'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "  0%|          | 0/269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 269/269 [00:01<00:00, 236.27it/s]\n",
      "4it [00:05,  1.46s/it]\n"
=======
      "100%|██████████| 269/269 [00:00<00:00, 635.17it/s]\n",
      "9it [00:17,  1.99s/it]\n"
>>>>>>> 5634803f820c05e4168f4dc3243aba6f96fddf71
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
<<<<<<< HEAD
      "\u001b[1;32mc:\\Users\\Nayel BLIDI\\Documents\\Kaggle\\dataHandler.ipynb Cell 13\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nayel%20BLIDI/Documents/Kaggle/dataHandler.ipynb#X15sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# If the batch refers to only one test subject, it is sent to the according subject csv file\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nayel%20BLIDI/Documents/Kaggle/dataHandler.ipynb#X15sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(current_id) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m (current_id \u001b[39min\u001b[39;00m series_id):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nayel%20BLIDI/Documents/Kaggle/dataHandler.ipynb#X15sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     \u001b[39m# If no csv already features this subject id, then it is created\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Nayel%20BLIDI/Documents/Kaggle/dataHandler.ipynb#X15sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     df_serie_id_csv \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(current_folder_path \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/series_id_data/\u001b[39m\u001b[39m{\u001b[39;00mseries_id[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nayel%20BLIDI/Documents/Kaggle/dataHandler.ipynb#X15sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     \u001b[39m# Concatenation of the stored subjct info to the info retreived from the batch\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nayel%20BLIDI/Documents/Kaggle/dataHandler.ipynb#X15sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     df_serie_id_csv \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([df_serie_id_csv[columns], df_current_batch[columns]], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Nayel BLIDI\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\Nayel BLIDI\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:583\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[0;32m    582\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[1;32m--> 583\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32mc:\\Users\\Nayel BLIDI\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1704\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1697\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[0;32m   1698\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1699\u001b[0m     \u001b[39m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1700\u001b[0m     (\n\u001b[0;32m   1701\u001b[0m         index,\n\u001b[0;32m   1702\u001b[0m         columns,\n\u001b[0;32m   1703\u001b[0m         col_dict,\n\u001b[1;32m-> 1704\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mread(  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m         nrows\n\u001b[0;32m   1706\u001b[0m     )\n\u001b[0;32m   1707\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1708\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\Nayel BLIDI\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39mread_low_memory(nrows)\n\u001b[0;32m    235\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mc:\\Users\\Nayel BLIDI\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:814\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Nayel BLIDI\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:875\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Nayel BLIDI\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:850\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Nayel BLIDI\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:861\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Nayel BLIDI\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:2029\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
=======
      "Cell \u001b[1;32mIn[63], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# If the batch refers to only one test subject, it is sent to the according subject csv file\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(current_id) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (current_id \u001b[38;5;129;01min\u001b[39;00m series_id):\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# If no csv already features this subject id, then it is created\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m     df_serie_id_csv \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_folder_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/series_id_data/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mseries_id\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;66;03m# Concatenation of the stored subjct info to the info retreived from the batch\u001b[39;00m\n\u001b[0;32m     45\u001b[0m     df_serie_id_csv \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_serie_id_csv[columns], df_current_batch[columns]], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1778\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1771\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m     (\n\u001b[0;32m   1775\u001b[0m         index,\n\u001b[0;32m   1776\u001b[0m         columns,\n\u001b[0;32m   1777\u001b[0m         col_dict,\n\u001b[1;32m-> 1778\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1779\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1780\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1782\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:230\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 230\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    232\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:808\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:866\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:852\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1973\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
>>>>>>> 5634803f820c05e4168f4dc3243aba6f96fddf71
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "\n",
    "batch_parquet = pq.ParquetFile(current_folder_path + \"/train_series.parquet\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Generation of n unique data info csv\n",
    "\"\"\"\n",
    "series_id = pd.unique(df_train_events[\"series_id\"])\n",
    "for batch in batch_parquet.iter_batches():\n",
    "    df_batch_train_series = batch.to_pandas()\n",
    "    columns = df_batch_train_series.columns\n",
    "    break\n",
    "    \n",
    "#df_batch_train_series = batch_parquet.iter_batches()[0].to_pandas()\n",
    "#columns = df_batch_train_series.columns\n",
    "print(columns)\n",
    "\n",
    "\"\"\"\n",
    "Generation of datafiles for each test subject (serie_id)\n",
    "\"\"\"\n",
    "for serie_id in tqdm(series_id):\n",
    "    df_train_series = pd.DataFrame([], columns=columns)\n",
    "    df_train_series.to_csv(f\"{current_folder_path}/series_id_data/{serie_id}.csv\")\n",
    "    \n",
    "df_mixed_train_series = pd.DataFrame([], columns=columns)\n",
    "df_mixed_train_series.to_csv(f\"{current_folder_path}/series_id_data/_mixed_batches.csv\")\n",
    "\n",
    "\"\"\"\n",
    "Sorting data of every test subject (serie_id)\n",
    "\"\"\"\n",
    "# Raw data is stored in a single large parquet file. \n",
    "# The data has to be opened and divided among the test subjects accordingly\n",
    "for batch in tqdm(batch_parquet.iter_batches()):\n",
    "    # Batch itteration\n",
    "    df_current_batch = batch.to_pandas()   \n",
    "    \n",
    "    # series_id featured in the current batch\n",
    "    current_id = pd.unique(df_current_batch[\"series_id\"])\n",
    "    \n",
    "    # If the batch refers to only one test subject, it is sent to the according subject csv file\n",
    "    if len(current_id) == 1 and (current_id in series_id):\n",
    "        # If no csv already features this subject id, then it is created\n",
    "        df_serie_id_csv = pd.read_csv(current_folder_path + f\"/series_id_data/{series_id[0]}.csv\")\n",
    "            \n",
    "        # Concatenation of the stored subjct info to the info retreived from the batch\n",
    "        df_serie_id_csv = pd.concat([df_serie_id_csv[columns], df_current_batch[columns]], axis=0)\n",
    "        df_serie_id_csv.to_csv(current_folder_path + f\"/series_id_data/{series_id[0]}.csv\")\n",
    "    \n",
    "    # If the batch features a rupture among the test subjects, it is stored to be sorted later on\n",
    "    else:\n",
    "        df_mixed_train_series = pd.concat([df_mixed_train_series[columns], df_current_batch[columns]], axis=0)\n",
    "\n",
    "df_mixed_train_series.to_csv(f\"{current_folder_path}/series_id_data/_mixed_batches.csv\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 34,
>>>>>>> 5634803f820c05e4168f4dc3243aba6f96fddf71
   "id": "d5c2aea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1953\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "for batch in batch_parquet.iter_batches():\n",
    "    c+=1\n",
    "print(c)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40d55a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
